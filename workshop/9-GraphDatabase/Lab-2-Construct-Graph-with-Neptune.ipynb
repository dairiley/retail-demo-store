{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 2 - Constructing the Graph Database\n",
    "In this lab we will ingest the product metadata into Neptune and construct a graph from it.\n",
    "\n",
    "## What is a Graph Database?\n",
    "\n",
    "A graph database is a database that stores relationships with a graph structure. Data is represented by nodes, edges and properties rather than tables or documents. In graph databases, we are able to transverse relationships very quickly as relationships between nodes are persisted in the database, rather than being caluclated at query times.\n",
    "\n",
    "[Amazon Neptune](https://aws.amazon.com/neptune/) is a high-performance graph database engine optimized for storing billions of relationships and querying the graph with millisecond latency. The nature of Neptune makes it a great tool for recommendation applications, as recommendations can be made quickly based on existing relationships.\n",
    "\n",
    "## Setup\n",
    "Just as in the first lab, we have to prepare our environment by importing dependencies and creating clients.\n",
    "\n",
    "### Update Dependencies\n",
    "To get started, we need to perform a bit of setup. First, we need to ensure that a current version of gremlinpython is currently installed. [Gremlin](https://tinkerpop.apache.org/gremlin.html) is the graph traversal language of [Apache Tinkerpop](https://tinkerpop.apache.org/). TinkerPop is a popular graph computing framework for both graph databases (OLTP) and graph analytic systems (OLAP).\n",
    "\n",
    "The following cell will update pip and install the latest gremlinpython library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall gremlinpython\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall nest-asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "__import__('IPython').embed()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies\n",
    "The following libraries are needed for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "import json\n",
    "import pandas as pd\n",
    "from gremlin_python.structure.graph import Graph\n",
    "from gremlin_python.process.graph_traversal import __\n",
    "from gremlin_python.process.strategies import *\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "from gremlin_python.driver.aiohttp.transport import AiohttpTransport\n",
    "from gremlin_python.process.traversal import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Clients\n",
    "Next we need to create the AWS service clients needed for this workshop.\n",
    "- **neptune**: This resource is used to create our Neptune DB cluster and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neptune = boto3.client('neptune')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables saved in Lab 1\n",
    "At the end of Lab 1 we saved some variables that we'll need in this lab. The following cell with load those variables into this lab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store -r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neptune Cluster and DB Instancee\n",
    "Currently, there is no Neptune cluster to store the relationships. We can create the Neptune DB cluster and the DB instance which will give us access to reader and a writer cluster endpoints. Creation will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = neptune.create_db_subnet_group(\n",
    "    DBSubnetGroupName='retail-demo-store-neptune-subnet-group',\n",
    "    DBSubnetGroupDescription='Subnet group for products Neptune cluster',\n",
    "    SubnetIds=[\n",
    "    ],\n",
    ")\n",
    "\n",
    "neptune_cluster = neptune.create_db_cluster(\n",
    "    DBClusterIdentifier='retail-demo-store-products-cluster',\n",
    "    Engine='neptune',\n",
    "    DBSubnetGroupName='retail-demo-store-neptune-subnet-group',\n",
    ")\n",
    "\n",
    "endpoint = neptune_cluster['DBCluster']['Endpoint']\n",
    "print('Neptune Endpoint:' + endpoint)\n",
    "\n",
    "neptune_db_instance = neptune.create_db_instance(\n",
    "    DBInstanceIdentifier='retail-demo-store-products-graph',\n",
    "    Engine='neptune',\n",
    "    DBInstanceClass='db.r6g.large',\n",
    "    DBClusterIdentifier=neptune_cluster['DBCluster']['DBClusterIdentifier']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for DB Instance to have active status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = None\n",
    "max_time = time.time() + 15*60\n",
    "while time.time() < max_time:\n",
    "    response = neptune.describe_db_instances(DBInstanceIdentifier=neptune_db_instance['DBInstance']['DBInstanceIdentifier'])\n",
    "    status = response['DBInstances'][0]['DBInstanceStatus']\n",
    "    print(\"Status: {}\".format(status))\n",
    "\n",
    "    if status == 'available':\n",
    "        break\n",
    "\n",
    "    time.sleep(30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Before we can start building the relationships between nodes and edges, we have to load the products data into a dataframe. This can be done by performing a scan on the DynamoDB table, and adding each data row to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DynamoDB Scan step:\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "ddb_response = ddb_table.scan()\n",
    "items = ddb_response['Items']\n",
    "\n",
    "# Fetch data into DF\n",
    "pd_data = []\n",
    "for data_row in items:\n",
    "    pd_data.append(data_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop columns from the data we are not interested in the relationships of to speed up processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_to_drop = ['sk', 'url', 'aliases']\n",
    "df_products = pd.DataFrame(pd_data)\n",
    "df_products.drop(cols_to_drop, inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Access Patterns\n",
    "To improve access patterns, we can create a dataframe for categories, which include a UUID for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_categories = df_products[['category']].drop_duplicates(subset=['category'])\n",
    "df_categories['category_id'] = [uuid.uuid4() for _ in range(len(df_categories.index))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for product styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_styles = df_products[['style']].drop_duplicates(subset=['style'])\n",
    "df_styles['style_id'] = [uuid.uuid4() for _ in range(len(df_styles.index))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest into Neptune\n",
    "As Neptune is a graph database, we have to insert the data according to this structure. This involves initializing a graph and traversing to add each product item by item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize Neptune connection with endpoint from created cluster\n",
    "\n",
    "graph = Graph()\n",
    "\n",
    "port = 8182\n",
    "endpoint = neptune_cluster['DBCluster']['Endpoint']\n",
    "endpoint = f'wss://{endpoint}:{port}/gremlin'\n",
    "\n",
    "graph=Graph()\n",
    "\n",
    "connection = DriverRemoteConnection(endpoint,'g',\n",
    "                 transport_factory=lambda:AiohttpTransport(call_from_event_loop=True))\n",
    "g = graph.traversal().withRemote(connection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Insert all products\n",
    "for index, row in df_products.iterrows():\n",
    "\n",
    "    # Insert item by item.\n",
    "    vertex_insert = g.addV('product') \\\n",
    "        .property(T.id, row['id']) \\\n",
    "        .property('product_name', row['name']) \\\n",
    "        .property('style', row['style']) \\\n",
    "        .property('gender_affinity', row['gender_affinity']) \\\n",
    "        .property('category', row['category']) \\\n",
    "        .property('featured', row['featured']) \\\n",
    "        .next()\n",
    "\n",
    "# Need performance improvements and optimizations\n",
    "# Updating items, to add Labels array (Neptune does not support dict/maps in addV).\n",
    "    for prop_label in json.loads(row['image_labels']):\n",
    "        if prop_label['Confidence'] > 75:\n",
    "            update_results = g.V(vertex_insert).property('labels_confidence_gt_75',\n",
    "                                                         prop_label['Name'].lower()).next()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then insert all the categories and styles created earlier as multi-label vertices to improve searchability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Insert all categories\n",
    "for index, row in df_categories.iterrows():\n",
    "    g.addV('category::{}'.format(row['category'])).property(T.id, str(row['category_id'])).property(\n",
    "        'name', row['category']).next()\n",
    "\n",
    "# Insert all styles\n",
    "for index, row in df_styles.iterrows():\n",
    "    g.addV('style::{}'.format(row['style'])).property(T.id, str(row['style_id'])).property(\n",
    "        'name', row['style']).next()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the insertions complete, the edges now have to be constructed to connect the graph vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add Category and Style IDs\n",
    "df_with_category_ids = pd.merge(df_products, df_categories, on='category', how='inner')\n",
    "df_with_cat_and_style_ids = pd.merge(df_with_category_ids, df_styles, on='style', how='inner')\n",
    "\n",
    "# Create Edges for Categories -> Styles\n",
    "df_edges_category_style = df_with_cat_and_style_ids[['category_id', 'style_id']].drop_duplicates(\n",
    "    subset=['category_id', 'style_id'])\n",
    "# Add edges for Categories -> Styles:\n",
    "for index, row in df_edges_category_style.iterrows():\n",
    "    cat_to_style_edge_insert = g.V(str(row['category_id'])).addE('has').to(__.V(str(row['style_id']))).next()\n",
    "    print(cat_to_style_edge_insert)\n",
    "\n",
    "# Create Edges for Styles --> Products\n",
    "df_edges_styles_products = df_with_cat_and_style_ids[['style_id', 'id']].drop_duplicates(subset=['style_id', 'id'])\n",
    "# Add edges for Styles --> Products (ID is the original column of a product_id):\n",
    "for index, row in df_edges_styles_products.iterrows():\n",
    "    style_to_prod_edge_insert = g.V(str(row['style_id'])).addE('has').to(__.V(str(row['id']))).next()\n",
    "    print(style_to_prod_edge_insert)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "With all the insertions complete and edges created, we close the connection to the graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2 Summary\n",
    "In this lab we created a Neptune cluster and wrote all our products data to our instance. We then constructed graph vertices between categories and styles which showcase the relationship between products.\n",
    "\n",
    "In the next lab, we will retrain Personalize with the image label data.\n",
    "\n",
    "## Store Variables Needed in the Next Lab\n",
    "We will pass some variables initialized in this lab by storing them in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db_cluster_identifier = neptune_cluster['DBCluster']['DBClusterIdentifier']\n",
    "%store db_cluster_identifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Continue to Lab 3\n",
    "Open [Lab 3](./Lab-3-Integrate-Neptune-with-OpenSearch.ipynb) to continue the workshop."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
