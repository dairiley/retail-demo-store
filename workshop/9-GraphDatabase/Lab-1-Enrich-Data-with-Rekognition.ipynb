{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Retail Demo Store - Neptune Workshop - Lab 1\n",
    "Welcome to the Retail Demo Store Neptune Workshop. In this module we will be using [Amazon Rekognition](https://aws.amazon.com/rekognition/) to enrich product data and use that data to create a graph database with [Amazon Neptune](https://aws.amazon.com/neptune/). Over these progressive labs, we will show how a graph database can be integrated with [Amazon OpenSearch Service](https://aws.amazon.com/opensearch-service/) to enhance user experience.\n",
    "You should complete the labs in the order specified below.\n",
    "\n",
    "## Workshop overview\n",
    "\n",
    "### Prerequisites\n",
    "This workshop requires that you have set up OpenSearch with the Retail Demo Store. You can do so by completing the OpenSearch lab (0-StartHere), or by building the index automatically as part of deployment (only applicable when creating the CloudFormation stack).\n",
    "\n",
    "### Labs\n",
    "- **Lab 1**: Introduction and data preparation (this lab) (_40 minutes_)\n",
    "- **Lab 2**: Ingest data into Neptune and construct graph (_25 minutes_)\n",
    "- **Lab 3**: Integrate Neptune with OpenSearch (_20 minutes_)\n",
    "\n",
    "### Cleanup\n",
    "The cleanup lab will tear down all of the Neptune resources created by the labs in this workshop.\n",
    "- **Lab 4**: Cleanup resources (_15 minutes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This workshop will be using the Python programming language and the AWS SDK for Python. Even if you are not fluent in Python, the code cells should be reasonably intuitive. In practice, you can use any programming language supported by the AWS SDK to complete the same steps from this workshop in your application environment.\n",
    "\n",
    "### Update Dependencies\n",
    "To get started, we need to perform a bit of setup. First, we need to ensure that a current version of botocore is currently installed. The botocore library is used by boto3, the AWS SDK library for Python.\n",
    "\n",
    "The following cell will update pip and install the latest botocore library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade --no-deps --force-reinstall botocore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies\n",
    "Next we need to import some dependencies and libraries needed to complete this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Clients\n",
    "Next we need to create the AWS service clients needed for this workshop.\n",
    "- **dynamodb**: This resource is used to get all the product information from the pre-existing DynamoDB table.\n",
    "- **s3**: This client is used to fetch product images from S3 in order to pass them into Rekognition.\n",
    "- **rekognition**: This client is used to generate labels from product images to enrich our product data.\n",
    "- **ssm**: This client is used to access application configuration details stored in the Systems Manager parameter store.\n",
    "- **servicediscovery**: This client is used to lookup the local IP addresses of the Retail Demo Store microservices that we'll need in the workshop.\n",
    "- **sagemaker**: This client is used to obtain the Uid of the notebook.\n",
    "\n",
    "Finally we'll lookup an identifier, stored as a resource tag in the SageMaker instance at deployment time. We need this tag to lookup resources we need throughout the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "s3 = boto3.client('s3')\n",
    "rekognition = boto3.client('rekognition')\n",
    "ssm = boto3.client('ssm')\n",
    "servicediscovery = boto3.client('servicediscovery')\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "with open('/opt/ml/metadata/resource-metadata.json') as f:\n",
    "    data = json.load(f)\n",
    "    resource_arn = data[\"ResourceArn\"]\n",
    "\n",
    "response = sagemaker.list_tags(ResourceArn = resource_arn)\n",
    "for tag in response['Tags']:\n",
    "    if tag['Key'] == 'Uid':\n",
    "        Uid = tag['Value']\n",
    "assert Uid is not None, 'Uid could not be determined from notebook instance tags'\n",
    "print('Uid:', Uid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup DynamoDB table\n",
    "When the Retail Demo Store stack was deployed in this account, a DynamoDB products table was created for you. The ARN of that table was stored in Systems Manager Parameter Store. Using the `ssm` boto3 client we created above, we can retrieve the table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_name = ssm.get_parameter(\n",
    "    Name='retaildemostore-stack-products-table'\n",
    ")\n",
    "ddb_table = dynamodb.Table(table_name['Parameter']['Value'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich Product Metadata with Rekognition\n",
    "To improve the relationships stored by Neptune, the existing product data needs to be enriched as the current product descriptions don't give us a huge amount of information. We used Rekognition for this purpose.\n",
    "\n",
    "Rekognition uses computer vision capabilities to extract information and images fromy our images and videos. As all the products in the Retail Demo Store have an image associated with them, we can use Rekognition to detect labels which give us insight into the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 Objects\n",
    "Before we can generate our image labels, we need to get the S3 bucket storing the images and perform a scan operation to get all the product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the S3 bucket from ssm\n",
    "bucketresponse = ssm.get_parameter(\n",
    "    Name='retaildemostore-stack-web-ui-bucket'\n",
    ")\n",
    "bucket = bucketresponse['Parameter']['Value']\n",
    "\n",
    "response = servicediscovery.discover_instances(\n",
    "    NamespaceName='retaildemostore.local',\n",
    "    ServiceName='products',\n",
    "    MaxResults=1,\n",
    "    HealthStatus='HEALTHY'\n",
    ")\n",
    "\n",
    "assert len(response['Instances']) > 0, 'Products service instance not found; check ECS to ensure it launched cleanly'\n",
    "\n",
    "products_service_instance = response['Instances'][0]['Attributes']['AWS_INSTANCE_IPV4']\n",
    "print('Products Service Instance IP: {}'.format(products_service_instance))\n",
    "\n",
    "response = requests.get('http://{}/products/all'.format(products_service_instance))\n",
    "products = response.json()\n",
    "products_df = pd.DataFrame(products)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "products_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the variables needed, we can run the `detect_labels` operation for each product image and update the DynamoDB record with the new labels. The process will take approximately 20 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bucket\n",
    "for product in products_df.itertuples():\n",
    "\n",
    "    # Construct s3 object key\n",
    "    product_image_name = re.sub('^http:\\/\\/.*.cloudfront.net\\/', '', product.image)\n",
    "\n",
    "    obj = s3.get_object(Bucket=bucket, Key=product_image_name)\n",
    "\n",
    "    # Get image labels\n",
    "    response = rekognition.detect_labels(Image={'S3Object': {'Bucket': bucket, 'Name': product_image_name}},\n",
    "                                         MaxLabels=10)\n",
    "\n",
    "    # Format response so we only have the keys we need\n",
    "    label_list = []\n",
    "    for label in response['Labels']:\n",
    "        label_list.append({\n",
    "            'Name': label['Name'],\n",
    "            'Confidence': label['Confidence']\n",
    "        })\n",
    "\n",
    "    # Update in DynamoDB\n",
    "    ddb_table.update_item(\n",
    "    Key={'id': product.id},\n",
    "    UpdateExpression=\"set image_labels = :image_labels\",\n",
    "    ExpressionAttributeValues={\n",
    "        ':image_labels': json.dumps(label_list),\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it\n",
    "Once the labels have finished generating and being inserted into DynamoDB, we can view a few of the results.\n",
    "\n",
    "Let's start by getting a random product row and viewing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "test_product = products_df.iloc[10]\n",
    "\n",
    "display(Image(url=test_product.image))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then query DynamoDB to get the image labels of our product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = ddb_table.get_item(Key={'id': test_product.id})\n",
    "\n",
    "json.loads(response['Item']['image_labels'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare each label with its level of confidence and see how it matches up. For the 10th product, Rekognition has 100% confidence that the image is both an accessory and a pair of glasses. \n",
    "\n",
    "Try changing the test product and see how results change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 1 Summary\n",
    "In this lab, you have used Rekognition to generate image labels for each product in the Retail Demo Store. In the next lab, you will ingest this new product data into Neptune and construct a graph from it.\n",
    "\n",
    "### Store Variables Needed in the Next Lab\n",
    "We will pass some variables initialized in this lab by storing them in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store table_name\n",
    "%store bucket\n",
    "%store Uid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Continue to Lab 2\n",
    "Open [Lab 2](./Lab-2-Construct-Graph-with-Neptune.ipynb) to continue the workshop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
