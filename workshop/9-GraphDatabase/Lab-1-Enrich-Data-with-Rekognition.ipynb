{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Retail Demo Store - Neptune Workshop - Lab 1\n",
    "Welcome to the Retail Demo Store Neptune Workshop. In this module we will be using [Amazon Rekognition](https://aws.amazon.com/rekognition/) to enrich product data and use that data to create a graph database with [Amazon Neptune](https://aws.amazon.com/neptune/). Over these progressive labs, we will show how a graph database can be integrated with [Amazon Personalize](https://aws.amazon.com/personalize/) and [Amazon OpenSearch Service](https://aws.amazon.com/opensearch-service/) to enhance user recommendations.\n",
    "You should complete the labs in the order specified below.\n",
    "\n",
    "## Workshop overview\n",
    "\n",
    "### Prerequestiies\n",
    "This workshop requires that you have set up Personalize with the Retail Demo Store. You can implement Personalize by completing the Personalization labs, or by building the campaigns automatically post-deployment (only applicable when creating the CloudFormation stack).\n",
    "\n",
    "### Labs\n",
    "- **Lab 1**: Introduction and data preparation (this lab) (_@todo Add time estimate_)\n",
    "- **Lab 2**: Ingest data into Neptune and construct graph (_@todo Add time estimate_)\n",
    "- **Lab 3**: Re-train Personalize with the data from Rekognition (_@todo Add time estimate_)\n",
    "- **Lab 4**: Integrate Neptune with OpenSearch (_@todo Add time estimate_)\n",
    "\n",
    "### Cleanup\n",
    "The cleanup lab will tear down all of the Neptune resources created by the labs in this workshop.\n",
    "- **Lab 6**: Cleanup resources (_@todo Add time estimate_)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "This workshop will be using the Python programming language and the AWS SDK for Python. Even if you are not fluent in Python, the code cells should be reasonably intuitive. In practice, you can use any programming language supported by the AWS SDK to complete the same steps from this workshop in your application environment.\n",
    "\n",
    "### Update Dependencies\n",
    "To get started, we need to perform a bit of setup. First, we need to ensure that a current version of botocore is currently installed. The botocore library is used by boto3, the AWS SDK library for Python.\n",
    "\n",
    "The following cell will update pip and install the latest botocore library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/rileydai/Projects/retail-demo-store/venv/lib/python3.8/site-packages (23.1)\r\n",
      "Collecting botocore\r\n",
      "  Using cached botocore-1.29.114-py3-none-any.whl (10.6 MB)\r\n",
      "Installing collected packages: botocore\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.29.114\r\n",
      "    Uninstalling botocore-1.29.114:\r\n",
      "      Successfully uninstalled botocore-1.29.114\r\n",
      "Successfully installed botocore-1.29.114\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade --no-deps --force-reinstall botocore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Dependencies\n",
    "Next we need to import some dependencies and libraries needed to complete this lab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mboto3\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import notebook_util\n",
    "import pandas as pd\n",
    "import requests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Clients\n",
    "Next we need to create the AWS service clients needed for this workshop.\n",
    "- **dynamodb**: This resource is used to get all the product information from the pre-existing DynamoDB table.\n",
    "- **s3**: This client is used to fetch product images from S3 in order to pass them into Rekognition.\n",
    "- **rekognition**: This client is used to generate labels from product images to enrich our product data.\n",
    "- **ssm**: This client is used to access application configuration details stored in the Systems Manager parameter store.\n",
    "- **servicediscovery**: this client is used to lookup the local IP addresses of the Retail Demo Store microservices that we'll need in the workshop\n",
    "\n",
    "Finally we'll lookup an identifier, stored as a resource tag in the SageMaker instance at deployment time. We need this tag to lookup resources we need throughout the labs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "s3 = boto3.client('s3')\n",
    "rekognition = boto3.client('rekognition')\n",
    "ssm = boto3.client('ssm')\n",
    "servicediscovery = boto3.client('servicediscovery')\n",
    "\n",
    "Uid = notebook_util.lookup_uid()\n",
    "assert Uid is not None, 'Uid could not be determined from notebook instance tags'\n",
    "print('Uid:', Uid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lookup DynamoDB table\n",
    "When the Retail Demo Store stack was deployed in this account, a DynamoDB products table was created for you. The ARN of that table was stored in Systems Manager Parameter Store. Using the `ssm` boto3 client we created above, we can retrieve the table ARN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_arn = ssm.get_parameter(\n",
    "    Name='retaildemostore-stack-table'\n",
    ")\n",
    "ddb_table = dynamodb.Table(table_arn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enrich Product Metadata with Rekognition\n",
    "To improve the relationships stored by Neptune, the existing product data needs to be enriched as the current product descriptions don't give us a huge amount of information. We used Rekognition for this purpose.\n",
    "\n",
    "Rekognition uses computer vision capabilities to extract information and images fromy our images and videos. As all the products in the Retail Demo Store have an image associated with them, we can use Rekognition to detect labels which give us insight into the product."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get S3 Objects\n",
    "Before we can generate our image labels, we need to get the S3 bucket storing the images and perform a scan operation to get all the product information."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the S3 bucket from ssm\n",
    "bucket = ssm.get_parameter(\n",
    "    Name='retaildemostore-stack-bucket'\n",
    ")\n",
    "products = ddb_table.scan()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have all the variables needed, we can run the `detect_labels` operation for each product image and update the DynamoDB record with the new labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for product in products['Items']:\n",
    "    # Construct s3 object key\n",
    "    product_image_name = f\"images/{product['Category']}/{product['Image']}\"\n",
    "\n",
    "    response = rekognition.detect_labels(Image={'S3Object': {'Bucket': bucket, 'Name': product_image_name}},\n",
    "                                       MaxLabels=10)\n",
    "    ddb_table.update_item(\n",
    "        Key={'id': product['ID']},\n",
    "        AttributeUpdates={'image_labels': response['Labels']}\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload Product Data for Personalize (Optional)\n",
    "As we want to use these new image labels to retrain Personalize later on, we need to update the products data in S3 that we use to train.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bucketresponse = ssm.get_parameter(\n",
    "    Name='retaildemostore-stack-bucket'\n",
    ")\n",
    "\n",
    "# We will use this bucket to store our training data:\n",
    "bucket = bucketresponse['Parameter']['Value']\n",
    "\n",
    "# We will build and upload our training data in this file:\n",
    "items_filename = \"items.csv\"\n",
    "\n",
    "print('Bucket: {}'.format(bucket))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As done in the initial training in the Personalization workshop, we have to load the columns we intend to use for the items dataset into a dataframe and rename the columns.\n",
    "\n",
    "We can re-fetch all the products data from the products service now that we've updated the DynamoDB table so the json response can easily be formatted as a dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get products service instance deployed in ECS\n",
    "response = servicediscovery.discover_instances(\n",
    "    NamespaceName='retaildemostore.local',\n",
    "    ServiceName='products',\n",
    "    MaxResults=1,\n",
    "    HealthStatus='HEALTHY'\n",
    ")\n",
    "assert len(response['Instances']) > 0, 'Products service instance not found; check ECS to ensure it launched cleanly'\n",
    "products_service_instance = response['Instances'][0]['Attributes']['AWS_INSTANCE_IPV4']\n",
    "\n",
    "# Fetch our products\n",
    "response = requests.get('http://{}/products/all'.format(products_service_instance))\n",
    "products = response.json()\n",
    "products_df = pd.DataFrame(products)\n",
    "\n",
    "# Load products into dataframe\n",
    "products_dataset_df = products_df[['id','price','category','style','description','gender_affinity','promoted', 'image_labels']]\n",
    "products_dataset_df = products_dataset_df.rename(columns = {'id':'ITEM_ID',\n",
    "                                                            'price':'PRICE',\n",
    "                                                            'category':'CATEGORY_L1',\n",
    "                                                            'style':'CATEGORY_L2',\n",
    "                                                            'description':'PRODUCT_DESCRIPTION',\n",
    "                                                            'gender_affinity':'GENDER',\n",
    "                                                            'promoted': 'PROMOTED',\n",
    "                                                            'image_labels': 'IMAGE_LABELS'})\n",
    "\n",
    "# Data normalization\n",
    "products_dataset_df['GENDER'].fillna('Any', inplace = True)\n",
    "products_dataset_df.loc[products_dataset_df['PROMOTED'] == 'true', 'PROMOTED'] = 'Y'\n",
    "products_dataset_df['PROMOTED'].fillna('N', inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save to CSV and upload to S3 bucket\n",
    "The items dataset is now ready so we can save the dataframe to a local CSV file before uploading to the S3 bucket. This new dataset will be used when we retrain Personalize with the new image label data in lab 3."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "products_dataset_df.to_csv(items_filename, index=False)\n",
    "s3.Bucket(bucket).Object(items_filename).upload_file(items_filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Lab 1 Summary\n",
    "In this lab, you have used Rekognition to generate image labels for each product in the Retail Demo Store. In the next lab, you will ingest this new product data into Neptune and construct a graph from it.\n",
    "\n",
    "### Store Variables Needed in the Next Lab\n",
    "We will pass some variables initialized in this lab by storing them in the notebook environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store ddb_table\n",
    "%store bucket\n",
    "%store items_filename\n",
    "%store Uid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Continue to Lab 2\n",
    "Open [Lab 2](./Lab-2-Construct-Graph-with-Neptune.ipynb) to continue the workshop."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
