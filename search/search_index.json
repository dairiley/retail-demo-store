{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>A sample retail web application and workshop platform intended as an educational tool for demonstrating how AWS infrastructure and services can be used to build compelling customer experiences for eCommerce, retail, and digital marketing use-cases.</p>"},{"location":"#build-status","title":"Build Status","text":"<p>This project is intended for educational purposes only and not for production use.</p> <p></p> <p>The Retail Demo Store is an eCommerce reference implementation designed to showcase how AWS services can be used to build compelling shopping experiences using modern architecture and design patterns.</p> <p>At the heart of the Retail Demo Store is a collection of polyglot microservices hosted in Amazon Elastic Container Service (AWS Fargate) that represent domain constructs such as products, carts, orders, and users as well as services for search and recommendations. While the web user interface is served by Amazon CloudFront and Amazon S3.</p> <p>The architecture is supported by several managed services including Amazon Cognito, Amazon Pinpoint, Amazon Personalize, and Amazon OpenSearch Service (successor to Amazon Elasticsearch Service). The web user interface is built using the Vue.js framework with AWS Amplify to provide integrations with Cognito for registration/authentication and event streaming to Pinpoint and Personalize (Event Tracker). Finally, AWS CodePipeline is leveraged to demonstrate how AWS development services can be used to orchestrate the build and deployment process with the Retail Demo Store.</p> <p></p>"},{"location":"#supported-regions","title":"Supported Regions","text":"<p>The Retail Demo Store has been tested in the AWS regions indicated in the deployment instructions below. Additional regions may be supported depending on service availability and having the Retail Demo Store's deployment resources staged to an S3 bucket in the targeted region.</p>"},{"location":"guide/getting-started/","title":"Getting Started","text":"<p>IMPORTANT NOTE: Deploying this demo application in your AWS account will create and consume AWS resources, which will cost money. In addition, some features such as account registration via Amazon Cognito and the messaging workshop for Amazon Pinpoint require users to provide a valid email address and optionally a phone number to demonstrate completely. Therefore, to avoid ongoing charges and to clean up all data, be sure to follow all workshop clean up instructions and shutdown/remove all resources by deleting the CloudFormation stack once you are finished.</p> <p>The Retail Demo Store experience is for demonstration purposes only. You must comply with all applicable laws and regulations, including any laws and regulations related to email or text marketing, in any applicable country or region.</p> <p>If you are a developer looking to contribute to the Retail Demo Store, please see the Developer section below.</p> <p>To get the Retail Demo Store running in your own AWS account, follow these instructions. If you are attending an AWS-led event where temporary AWS accounts are provided, this has likely already been done for you. Check with your event administrators.</p>"},{"location":"guide/getting-started/#step-1-get-an-aws-account","title":"Step 1 - Get an AWS Account","text":"<p>If you do not have an AWS account, please see How do I create and activate a new Amazon Web Services account?</p>"},{"location":"guide/getting-started/#step-2-log-into-the-aws-console","title":"Step 2 - Log into the AWS Console","text":"<p>Log into the AWS console if you are not already.</p> <p>Note: If you are logged in as an IAM user, ensure your account has permissions to create and manage the necessary resources and components for this application.</p>"},{"location":"guide/getting-started/#step-3-deploy-to-your-aws-account","title":"Step 3 - Deploy to your AWS Account","text":"<p>The following CloudFormation launch options will set the deployment approach to \"CodeCommit\". You can ignore the GitHub related template parameters. After clicking one of the Launch Stack buttons below, follow the procedures to launch the template. Be sure to enter a CloudFront stack name in lowercase letters (numbers and hyphens are okay too).</p> <p>With this deployment option, the CloudFormation template will import the Retail Demo Store source code into a CodeCommit repository in your account and setup CodePipeline to build and deploy into ECS from that respository.</p> Region name Region code Launch US East (N. Virginia) us-east-1 US West (Oregon) us-west-2 Europe (Ireland) eu-west-1 Asia Pacific (Tokyo) ap-northeast-1 Asia Pacific (Sydney) ap-southeast-2 <p>The CloudFormation deployment will take approximately 40 minutes to complete.</p>"},{"location":"guide/getting-started/#notes","title":"Notes:","text":""},{"location":"guide/getting-started/#amazon-personalize-campaigns","title":"Amazon Personalize Campaigns","text":"<p>If you chose to have the Amazon Personalize campaigns automatically built post-deployment, this process will take an additional 2-2.5 hours. This process happens in the background so you don't have to wait for it to complete before exploring the Retail Demo Store application and architecture. Once the Personalize campaigns are created, they will be automatically activated in the Web UI and Recommendations service. You can monitor the progress in CloudWatch under the <code>/aws/lambda/RetailDemoStorePersonalizePreCreateCampaigns</code> log group.</p>"},{"location":"guide/getting-started/#amazon-pinpoint-campaigns","title":"Amazon Pinpoint Campaigns","text":"<p>If you chose to have the Amazon Pinpoint campaigns automatically built (\u2018Auto-Configure Pinpoint\u2019 is set to \u2018Yes\u2019 in the CloudFormation template), this process will take an additional 20-30 minutes. Once the Pinpoint campaigns are created, they will be automatically visbile in the Web UI. However, there are some manual steps described below that are required for enabling the Pinpoint channels.</p>"},{"location":"guide/getting-started/#pinpoint-emails","title":"Pinpoint Emails:","text":"<p>PinpointEmailFromAddress: By Default, AWS Accounts have  emails set up in a sandbox environement. To enable the functionality, you need to complete either of the following manual steps. * Verifying the email addresses you want to send and receive emails from. More info here. This is the easiest and recommended approach for demos and workshops. * Request to be removed from the sandbox environment. More info here. This is recommended only for production workloads and the Retail Demo Store is intended to be used for demonstration purposes only.</p>"},{"location":"guide/getting-started/#pinpoint-sms","title":"Pinpoint SMS","text":"<p>PinpointSMSLongCode: A dedicated long code (i.e. a phone number) obtained for Amazon Pinpoint to send and receive messages at. You also need to enable two way SMS for this long code using Pinpoint. Follow steps 2 and 3 in the Enable Pinpoint SMS Channel &amp; Obtain Dedicated Long Code section of the Pinpoint workshop to get a long code and enable two way SMS for it. When deploying Retail Demo Store, enter the number as a parameter. The number should be formatted along with the country code and without any spaces or brackets. For Example: enter \u201c+1XXXXXXXXXX\u201d for a long code based in the United States.</p>"},{"location":"guide/getting-started/#step-4-using-the-retail-demo-store-web-application","title":"Step 4 - Using the Retail Demo Store Web Application","text":"<p>Once you launch the CloudFormation stack, all of the services will go through a build and deployment cycle and deploy the Retail Demo Store.</p> <p>Compiling and deploying the web UI application and the services it uses can take some time. You can monitor progress in CodePipeline. Until this completes, you may see a Sample Application when accessing the public WebUI URL.</p> <p>You can find the URL for the Retail Demo Store Web UI in the Outputs of your main CloudFormation stack (called <code>retaildemostore</code> unless you changed that option in the steps above).</p> <p>Look for the \"WebURL\" output parameter.</p> <p>You can read more detailed instructions on how to demo the Retail Demo Store in the Demo section at the end of this document.</p>"},{"location":"guide/troubleshooting/","title":"Troubleshoot","text":""},{"location":"guide/troubleshooting/#known-issueslimitations","title":"Known Issues/Limitations","text":"<ul> <li>The application was written for demonstration and education purposes and not for production use.</li> <li>You currently cannot deploy this project multiple times in the same AWS account and the same AWS region. However, you can deploy the project into separate supported regions within the same AWS account.</li> <li>Make sure your CloudFormation stack name uses all lowercase letters.</li> <li>Currently only tested in the AWS regions provided in the deployment instructions above. The only limitation for deploying into other regions is availability of all required services.<ul> <li>Amazon IVS is currently only supported in the N. Virginia (us-east-1), Oregon (us-west-2), and Ireland (eu-west-1) regions. Therefore, to deploy the Retail Demo Store in a region that does not support IVS, be sure to select to use the Default IVS Streams CloudFormation template parameter.</li> </ul> </li> </ul>"},{"location":"guide/troubleshooting/#troubleshooting-faqs","title":"Troubleshooting / FAQs","text":"<p>Q: When accessing the Retail Demo Store web application after deploying the project, a CloudFront error is displayed. What's wrong?</p> <p>A: Sign in to the AWS account/region where the project was deployed and browse to CodePipeline. Verify that the pipeline with \"WebUIPipeline\" in the name has successfully been built. If it failed, inspect the details of the Build stage to diagnose the root cause.</p> <p>Q: When accessing the Retail Demo Store web application after deploying the project, the home page shows spinning icons and products are never loaded. What's wrong?</p> <p>A: The most likely cause is an error building or deploying one or more of the microservices. Sign in to the AWS account/region where the project was deployed and browse to CodePipeline. Verify that all of the Retail Demo Store pipelines have completed successfully. Inspect the details for any that have failed to determine the root cause. Sometimes just manually triggering a build/deploy will resolve the issue.</p> <p>Q: This project is expensive to run (or keep running). How can I reduce the running cost of a deployment?</p> <p>A: The most costly service in the project for an idle deployment is Amazon Personalize. You can eliminate Personalize idle costs by stopping all Amazon Personalize recommenders and deleting all campaigns in the Retail Demo Store dataset group for Personalize. This just shuts down the real-time inference endpoints; the datasets and ML models will remain. You should also change all of the recommender and campaign ARN parameter values in the AWS Systems Manager Parameter Store to <code>NONE</code>, leaving the parameter values for filters and the event tracker alone. These parameter names start with <code>/retaildemostore/personalize/</code> (e.g., <code>/retaildemostore/personalize/recommended-for-you-arn</code>). Once you complete these steps, the storefront will fall back to default behavior for recommending products from the catalog. To reactive Personalize, start the recommenders and create campaigns and then set the recommender and/or campaign ARNs back in the Systems Manager Parameter Store. The storefront will automatically start showing recommendations from Personalize again.</p>"},{"location":"guide/troubleshooting/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you encounter a bug, please create a new issue with as much detail as possible and steps for reproducing the bug. See the Contributing Guidelines for more details.</p>"},{"location":"guide/local-development/local-development-instructions/","title":"Local Development Instructions","text":"<p>The Retail Demo Store's web services such as users, carts, orders, products, and others can be run locally on your development system using Docker Compose. You can choose to run them all locally or just one or two locally and the rest running in your AWS account. For example, suppose you're working on an enhancement or fix in the products service. You can run just that service locally to test your changes while all of the other services are running in your AWS account. If your changes require UI testing, you can run the web-ui in a local container as well configured to connect to your local product service instance while still having both of them connect to the other services running in your AWS account.</p> <p>Before you can run the Retail Demo Store web services locally, you must first deploy the Retail Demo Store project to your AWS account and then clone this repository to your local machine. The instructions below provide additional details on configuration and how to setup the services to run locally. The docker-compose.yml file includes the configuration used by Docker Compose. Note that there are some dependencies between services which are noted.</p>"},{"location":"guide/local-development/local-development-instructions/#configuring-your-environment","title":"Configuring your Environment","text":"<p>Besides cloning this repository to your local system, you also need to have the AWS CLI installed and configured locally.</p> <p>Docker Compose will load the <code>.env</code> file to resolve environment variables referenced in the docker-compose.yml file. You can copy the .env.template file to .env as a starting point. This is where you can customize variables to match your desired configuration.</p> <p>You can find the common environment variables from your deployed stack in the CloudFormation output name <code>ExportEnvVarScript</code>. Use this CLI to get the output in a proper format.</p> <pre><code>aws cloudformation describe-stacks --stack-name retaildemostore \\\n  --region REGION \\\n  --query \"Stacks[0].Outputs[?OutputKey=='ExportEnvVarScript'].OutputValue\" \\\n  --output text\n</code></pre> <p>Then you can copy and override variables for each service in your .env file.</p>"},{"location":"guide/local-development/local-development-instructions/#amazon-ecr-authorization","title":"Amazon ECR authorization","text":"<p>Since some of the Docker images are hosted in Amazon ECR, you must authenticate your shell session before running docker-compose. Otherwise, the images will not be able to be downloaded. Run the following command to authenticate before running docker-compose. You should only have to do this once per shell session.</p> <pre><code>aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws\n</code></pre>"},{"location":"guide/local-development/local-development-instructions/#aws-credentials","title":"AWS credentials","text":"<p>Some services, such as the products and recommendations services, need to access AWS services running in your AWS account from your local machine. Given the differences between these container setups, different approaches are needed to pass in the AWS credentials needed to make these connections. For example, for the recommendations service we can map your local <code>~./.aws</code> configuration directory into the container's <code>/root</code> directory so the AWS SDK in the container can pick up the credentials it needs. Alternatively, since the products service is packaged from a scratch image, credentials must be passed using the <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_SESSION_TOKEN</code> environment variables. In this case, rather than setting these variables in <code>.env</code> and risk exposing these values, consider setting these three variables in your shell environment. The following command can be used to obtain a session token which can be used to set your environment variables in your shell.</p> <p>DynamoDB is one dependency that can be run locally rather than connecting to the real DynamoDB. This makes it easier to run services like the products service completely local to you computer.</p> <pre><code>foo@bar:~$ aws sts get-session-token\n</code></pre> <p>Docker compose will still pick variables set in your shell when building and launching the services.</p>"},{"location":"guide/local-development/local-development-instructions/#run-all-services","title":"Run All Services","text":"<p>The following command will build and launch all Retail Demo Store web services in your local Docker engine.</p> <pre><code>foo@bar:~$ docker compose up --build\n</code></pre>"},{"location":"guide/local-development/local-development-instructions/#run-specific-services","title":"Run Specific Services","text":"<p>You can also choose to run specific services locally by appending the service names to the above command. For example, the following command builds and launches the products and web-ui services only. Note that some configuration of the web-ui environment will likely be needed to match your configuration.</p> <pre><code>foo@bar:~$ docker compose up --build products web-ui\n</code></pre> <p>For instructions specific to each Retail Demo Store web service, view the README page in each service sub-directory.</p>"},{"location":"guide/local-development/local-development-instructions/#web-ui-service","title":"Web UI Service","text":"<p>When deployed to AWS, the Web UI is hosted in an S3 bucket and served by CloudFront. For local development, you can deploy the Web UI in a Docker container. Since the Web UI makes REST API calls to all of the other services, you can configure the <code>web-ui/.env</code> file for which there is an example at web-ui/.env.template to point to services running either locally or deployed on AWS or a combination. Just update the appropiate environment variables to match your desired configuration.</p>"},{"location":"guide/local-development/local-development-instructions/#swagger-ui","title":"Swagger UI","text":"<p>There is a <code>swagger-ui</code> service in the <code>docker-compose.yml</code>. You can access it via localhost:8081. From there, you can select which service you want to check and send request agains the service via Swagger UI.</p> <p>The <code>Dockerfile</code> of <code>swagger-ui</code> copies OpenAPI spec from each service (located at <code>&lt;serviceName&gt;/openapi/spec.yaml</code>). If you add a new service, please ensure that you write the OpenAPI spec and update the <code>Dockerfile</code> to copy yours.</p>"},{"location":"guide/services/alexa/","title":"Alexa Skill for C-Store Demo","text":"<p>For more details, including how to deploy, see <code>workshops/5-Conversational/5.2-AlexaHandsfree.md</code>.</p>"},{"location":"guide/services/aws-lambda/","title":"AWS Lambda Functions","text":"<p>The Lambda functions in this folder are used to support the Retail Demo Store deployment as custom resources, to automatically build Amazon Personalize campaigns, or to support service integrations (i.e. between Pinpoint and Personalize).</p>"},{"location":"guide/services/carts/","title":"Carts Service","text":"<p>The Carts web service provides a RESTful API for adding, changing, and deleting shopping carts. The Web UI makes calls to this service as a user adds and removes items from their cart and during checkout.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Carts service as a Docker container to Amazon ECS behind an Application Load Balancer. The Carts service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/carts/#local-development","title":"Local Development","text":"<pre><code>foo@bar:~$ docker compose up --build -d carts\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8003.</p>"},{"location":"guide/services/carts/#testing","title":"Testing","text":"<p>To run integration tests for the carts service a Python virtual environment and local dynamodb is required. You must have Python 3.8+ installed on your system to run the commands below. The commands are written to be ran from the test directory of the carts service (<code>src/carts/test</code>).</p>"},{"location":"guide/services/carts/#run-tests","title":"Run Tests","text":"<p>To run integration tests for the carts service a Python virtual environment is required. You must have Python 3.8+ installed on your system to run the commands below. The commands are written to be ran from the test directory of the carts service (<code>src/carts/test</code>).</p> <p>The following command will create a virtual environment. </p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Some environment variables are required to run the tests and need to be added to the virtual environment. The example below will work for local development. Change as required depending on environment.</p> <pre><code>echo '\nexport CARTS_API_URL=\"http://localhost:8003\"\nexport TEST_USERNAME=\"user1344\"'&gt;&gt; .venv/bin/activate\n</code></pre> <p>To activate and enter the virtual environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>To install requirements for the integration tests.</p> <pre><code>pip install -r integ/requirements.txt\n</code></pre> <p>To run the tests.</p> <pre><code>pytest integ/test_carts.py\n</code></pre> <p>You can exit the virtual environment with <code>deactivate</code>.</p> <p>If you want to edit the request bodies for any of the <code>PUT</code> or <code>POST</code> request tests you can do so in <code>json_request_bodies.json</code></p>"},{"location":"guide/services/location/","title":"Location Service","text":"<p>The location web service provides an API for retrieving store locations and  customer routes to support to Location Services demo in the Retail Demo Store. To use the demo, see \"Retail Geofencing and Location-aware Personalization\" in the in-app Demo Guide.  </p> <p>This service has two APIs. Check Swagger UI for the API details.</p>"},{"location":"guide/services/location/#local-development","title":"Local Development","text":"<p>The location service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build location\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8008.</p>"},{"location":"guide/services/offers/","title":"Offers Service","text":"<p>The Offers web service provides a RESTful API for retrieving coupons. </p> <p>To see this used, see \"Retail Geofencing and Location-aware Personalization\" in the in-app Demo Guide. </p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Offers service as a Docker container to Amazon ECS behind an Application Load Balancer. The Offers service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/offers/#local-development","title":"Local Development","text":"<p>The Offers service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build offers\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8008.</p>"},{"location":"guide/services/orders/","title":"Orders Service","text":"<p>The Orders web service provides a RESTful API for creating and retrieving orders. The Web UI makes calls to this service when a user goes through the checkout process or when viewing their orders.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Orders service as a Docker container to Amazon ECS behind an Application Load Balancer. The Orders service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/orders/#local-development","title":"Local Development","text":"<p>The Orders service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker-compose up --build orders\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8004.</p>"},{"location":"guide/services/orders/#testing","title":"Testing","text":"<p>To run integration tests for the Orders service a Python virtual environment is required. You must have Python 3.8+ installed on your system to run the commands below. The commands are written to be ran from the test directory of the orders service (<code>src/orders/test</code>).</p> <p>The following command will create a virtual environment. </p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Some environment variables are required to run the tests and need to be added to the virtual environment. The example below will work for local development. Change as required depending on environment.</p> <pre><code>echo '\nexport ORDERS_API_URL=\"http://localhost:8004\"\nexport TEST_ORDER_ID=\"1\"\nexport TEST_USERNAME=\"user1344\"' &gt;&gt; .venv/bin/activate\n</code></pre> <p>To activate and enter the virtual environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>To install requirements for the integration tests.</p> <pre><code>pip install -r integ/requirements.txt\n</code></pre> <p>To run the tests.</p> <pre><code>pytest integ/test-orders.py\n</code></pre> <p>You can exit the virtual environment with <code>deactivate</code>.</p> <p>If you want to edit the request bodies for any of the <code>PUT</code> or <code>POST</code> request tests you can do so in <code>json_request_bodies.json</code></p>"},{"location":"guide/services/products/","title":"Products Service","text":"<p>The Products web service provides a RESTful API for retrieving product information. The Web UI makes calls to this service when a user is viewing products and categories and the Personalize workshop connects to this service to retrieve product information for building the items dataset.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Products service as a Docker container in Amazon ECS behind an Application Load Balancer. The Products service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/products/#local-development","title":"Local Development","text":"<p>The Products service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. Since the Products service has a dependency on DynamoDB as its datastore, you can either connect to DynamoDB in your AWS account or run DynamoDB locally (default). The docker-compose.yml and template <code>.env</code> (.env.template) is already setup to run DynamoDB locally in Docker. If you want to connect to the real DynamoDB instead, you will need to configure your AWS credentials and comment the <code>DDB_ENDPOINT_OVERRIDE</code> environment variable since it is checked first. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build products\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8001.</p> <p>Alternatively, you can run the Products service directly, although you will need to setup the required environment variables (See the .env.template file mentioned above) and setup DynamoDB locally or through your AWS account.</p> <p>From the (<code>src/products/src</code>) directory setup a virtual env:</p> <pre><code>python3 -m venv .venv\n</code></pre> <p>To activate and enter the virtual environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Install the service dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Set the required Environment variables.  For development, you can set the <code>FLASK_CONFIG</code> env variable to <code>Development</code></p> <pre><code>export FLASK_CONFIG=Development\n</code></pre> <p>To run the service you can either type: </p> <pre><code>flask run\n</code></pre> <p>or</p> <pre><code>python3 wsgi.py\n</code></pre> <p>The Products service listens on port <code>8001</code>, you can change this by setting the <code>FLASK_RUN_PORT</code> environment variable, e.g:</p> <pre><code>set FLASK_RUN_PORT=xxxx\n</code></pre>"},{"location":"guide/services/products/#initializing-the-database","title":"Initializing the Database","text":"<p>The DynamoDB tables can be created and loaded with sample data by calling the init endpoint:</p> <pre><code>POST http://localhost:8001/init\n</code></pre>"},{"location":"guide/services/products/#products-api","title":"Products API","text":"<p>The following entrypoints are supported by the Products service</p>"},{"location":"guide/services/products/#get","title":"GET /","text":"<p>Displays the service welcome page.</p>"},{"location":"guide/services/products/#get-productsall","title":"GET /products/all","text":"<p>Returns details on all products.</p>"},{"location":"guide/services/products/#get-productsidproductids","title":"GET /products/id/{productIDs}","text":"<p>Returns details on the product(s) identified by <code>{productIDs}</code>. Multiple product IDs can be specified by separating each product ID by a comma. If a single product ID is specified, a single product will be returned. Otherwise, if multiple product IDs are specified, an array of products will be returned.</p>"},{"location":"guide/services/products/#get-productsfeatured","title":"GET /products/featured","text":"<p>Returns details on all featured products. Featured products are those with featured attribute equal to true.</p>"},{"location":"guide/services/products/#get-productscategorycategoryname","title":"GET /products/category/{categoryName}","text":"<p>Returns details on all products within the category with the name <code>{categoryName}</code>.</p>"},{"location":"guide/services/products/#put-productsidproductid","title":"PUT /products/id/{productID}","text":"<p>Updates the product identified by <code>{productID}</code>.</p>"},{"location":"guide/services/products/#delete-productsidproductid","title":"DELETE /products/id/{productID}","text":"<p>Deletes the product identified by <code>{productID}</code>.</p>"},{"location":"guide/services/products/#post-products","title":"POST /products","text":"<p>Creates a new product.</p>"},{"location":"guide/services/products/#put-productsidproductidinventory","title":"PUT /products/id/{productID}/inventory","text":"<p>Updates the current inventory value for the product identified by <code>{productID}</code>.</p>"},{"location":"guide/services/products/#get-categoriesall","title":"GET /categories/all","text":"<p>Returns details on all categories.</p>"},{"location":"guide/services/products/#get-categoriesidcategoryid","title":"GET /categories/id/{categoryID}","text":"<p>Returns details on the category identified by <code>{categoryID}</code>.</p>"},{"location":"guide/services/products/#testing","title":"Testing","text":"<p>To run integration tests for the Products service a Python virtual environment is required. You must have Python 3.8+ installed on your system to run the commands below. The commands are written to be ran from the test directory of the products service (<code>src/products/test</code>).</p> <p>The following command will create a virtual environment. </p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Some environment variables are required to run the tests and need to be added to the virtual environment. The example below will work for local development. Change as required depending on environment.</p> <pre><code>echo '\nexport PRODUCTS_API_URL=\"http://localhost:8001\"\nexport TEST_PRODUCT_ID=\"8bffb5fb-624f-48a8-a99f-b8e9c64bbe29\"\nexport TEST_CATEGORY_NAME=\"tools\"\nexport TEST_CATEGORY_ID=\"16\"' &gt;&gt; .venv/bin/activate\n</code></pre> <p>To activate and enter the virtual environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>To install requirements for the integration tests.</p> <pre><code>pip install -r integ/requirements.txt\n</code></pre> <p>To run the tests.</p> <pre><code>pytest integ/test-products.py\n</code></pre> <p>You can exit the virtual environment with <code>deactivate</code>.</p> <p>If you want to edit the request bodies for any of the <code>PUT</code> or <code>POST</code> request tests you can do so in <code>json_request_bodies.json</code></p>"},{"location":"guide/services/recommendations/","title":"Recommendations Service","text":"<p>The Recommendations web service provides a RESTful API for retrieving personalized product recommendations,  related products, product reranking, and suggested discounts (powered by Amazon Personalize).   The Web UI makes calls to this service when a user is viewing the home view (recommended products), product detail view (related products), or the category view (personalized ranking of products). If Amazon Personalize campaigns have been created for these use-cases (either by the deployment Lambda option or by stepping through the Personalization workshop), then those campaigns will be called by the Recommendations service. Otherwise, the service will call the Products service to provide a suitable default behavior such as displaying featured products or products from the same category as the displayed product.</p> <p>This service also provides support for running experiments for personalization approaches using techniques such as A/B testing, interleaving results testing, and multi-armed bandit testing. The Experimentation workshops are designed to walk you through how to setup, run, and evaluate experiments.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Recommendations service as a Docker container to Amazon ECS behind an Application Load Balancer. The Recommendations service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/recommendations/#local-development","title":"Local Development","text":"<p>The Recommendations service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build recommendations\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8005.</p>"},{"location":"guide/services/search/","title":"Search Service","text":"<p>The Search web service provides a RESTful API for retrieving product information based on a search term. The Web UI makes calls to this service when a user performs a search. Internally, this service makes calls to an OpenSearch cluster for search results. When deployed on AWS, Amazon OpenSearch Service is used. When deployed locally, a local OpenSearch node is used for searches.</p> <p>When the Search service and Amazon OpenSearch are initially deployed to your AWS account, product information is not present in an index and therefore searches from the Web UI will not return results. There are two options for indexing products in OpenSearch when deploying to AWS. First, when deploying the Retail Demo Store project, the CloudFormation template has an option to index the product catalog in OpenSearch as part of the deployment process. The second option is to step through the Search workshop.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Search service as a Docker container to Amazon ECS behind an Application Load Balancer. The Search service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/search/#local-development","title":"Local Development","text":"<p>The Search service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy OpenSearch and the Search service locally.</p> <pre><code>foo@bar:~$ docker compose up --build opensearch search\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8006.</p>"},{"location":"guide/services/search/#indexing-products-locally","title":"Indexing Products Locally","text":"<p>As explained above, when the Search service and OpenSearch are deployed, the product information does not exist in an OpenSearch index. When deploying locally, you can use the local_index_products.py script after starting the <code>opensearch</code> Docker container to create and load the products index.</p>"},{"location":"guide/services/users/","title":"Users Service","text":"<p>The Users web service provides a RESTful API for creating, updating, and retrieving users. The Web UI makes calls to this service when a user signs up or updates their profile.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Users service as a Docker container to Amazon ECS behind an Application Load Balancer. The Users service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/users/#user-test-data","title":"User Test Data","text":"<p>The Users service comes preloaded with 5,000 fake user profiles. The generate_users_json.py script was used to create these profiles. The resulting profiles data file is bundled with the Retail Demo Store deployment. Therefore, you should not need to run the generate users script under normal conditions.</p> <p>The reason why so many profiles are preloaded is to support the sample sizes needed to simulate experiements in the Experimentation workshops.</p>"},{"location":"guide/services/users/#local-development","title":"Local Development","text":"<p>The Users service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build users\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8002.</p>"},{"location":"guide/services/users/#testing","title":"Testing","text":"<p>To run integration tests for the Users service a Python virtual environment is required. You must have Python 3.8+ installed on your system to run the commands below. The commands are written to be ran from the test directory of the Users service (<code>src/users/test</code>).</p> <p>The following command will create a virtual environment. </p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Some environment variables are required to run the tests and need to be added to the virtual environment. The example below will work for local development. Change as required depending on environment.</p> <pre><code>echo '\nexport USERS_API_URL=\"http://localhost:8002\"\nexport TEST_USER_ID=\"1\"\nexport TEST_USERNAME=\"user1\"\nexport TEST_IDENTITY_ID=\"eu-west-1:12345678-1234-1234-1234-c777c9720775\"\nexport TEST_PRIMARY_PERSONA=\"tools\"\nexport TEST_AGE_RANGE=\"18-24\"' &gt;&gt; .venv/bin/activate\n</code></pre> <p>To activate and enter the virtual environment.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>To install requirements for the integration tests.</p> <pre><code>pip install -r integ/requirements.txt\n</code></pre> <p>To run the tests.</p> <pre><code>pytest integ/test-users.py\n</code></pre> <p>You can exit the virtual environment with <code>deactivate</code>.</p> <p>If you want to edit the request bodies for any of the <code>PUT</code> or <code>POST</code> request tests you can do so in <code>json_request_bodies.json</code></p>"},{"location":"guide/services/videos/","title":"Videos Service","text":"<p>The Videos service streams product videos and synchronised metadata to Amazon Interactive Video Service and provides stream metadata (stream endpoints and products contained within the stream) via a Flask API. The Web UI makes calls to the service when a user views the 'Live' view. The endpoint provides a list of stream ingest endpoints, each with a list of their associated products, allowing the UI to present all products from the video before they appear in the stream.</p> <p>When deployed to AWS, CodePipeline is used to build and deploy the Videos service as a Docker container to Amazon ECS behind an Application Load Balancer. The Videos service can also be run locally in a Docker container. This makes it easier to iterate on and test changes locally before commiting.</p>"},{"location":"guide/services/videos/#deploying-channels-streaming-video","title":"Deploying Channels &amp; Streaming Video","text":"<p>IVS channels are created and managed by the CloudFormation template. The default CloudFormation settings do not create any new IVS streams - instead the demo directs the UI to four externally hosted IVS streams.</p> <p>To create and use IVS channels hosted in your own account, the option 'Use default IVS streams' should be set to 'No' when deploying CloudFormation. In this case, one IVS channel will be created for each '.mkv' video found in the <code>videos/</code> path of the staging S3 bucket. These videos should be uploaded by running the provided staging script - any videos in the local <code>videos/</code> directory will be uploaded.</p> <p>IMPORTANT: Amazon IVS is currently only supported in the N. Virginia (us-east-1), Oregon (us-west-2), and Ireland (eu-west-1) regions. Therefore, to deploy the Retail Demo Store in a region that does not support IVS, be sure to select to use the Default IVS Streams CloudFormation template parameter.</p>"},{"location":"guide/services/videos/#custom-videos-metadata","title":"Custom Videos &amp; Metadata","text":"<p>To enable full UI integration with custom videos, metadata must be embedded into the .mkv file.</p> <p>Metadata must be created in the <code>.srt</code> format, with each timestamped entry containing data in the form: <code>{\"productId\": &lt;PRODUCT_ID&gt;}</code>. The Videos service sends the metadata at the start of the timestamp. The latter section of the timestamp is not used. The file can either be edited manually or using an SRT editor (either software or online). An example metadata file can be seen here.</p> <p>This metadata can then be combined with a video file to create an encoded <code>.mkv</code> file with embedded metadata by running the following command:</p> <pre><code>ffmpeg -i &lt;INPUT_VIDEO_PATH&gt; -i &lt;INPUT_METADATA_PATH&gt;.srt -vf scale=640x360 -c:v libx264  \\\n-pix_fmt yuv420p -profile:v main -tune fastdecode -x264opts \u201cnal-hrd=cbr:no-scenecut\u201d -minrate 3000 \\\n-maxrate 3000  -g 60 -c:a aac -b:a 160k -ac 2 -ar 44100 &lt;OUTPUT_FILE_PATH&gt;.mkv\n</code></pre> <p>An <code>.mkv</code> file created with this command is ready to be staged and should provide optimal UI integration. The command also pre-encodes the video in a format designed to reduce the CPU &amp; memory requirements of the Videos service.</p>"},{"location":"guide/services/videos/#local-development","title":"Local Development","text":"<p>The Videos service can be built and run locally (in Docker) using Docker Compose. See the local development instructions for details. From the <code>../src</code> directory, run the following command to build and deploy the service locally.</p> <pre><code>foo@bar:~$ docker compose up --build videos\n</code></pre> <p>Once the container is up and running, you can access it in your browser or with a utility such as Postman at http://localhost:8007.</p>"},{"location":"partner-integrations/partner-integrations/","title":"Partner integrations","text":"<p>AWS partners have developed workshop content that enable you to learn how to integrate their solutions with the Retail Demo Store and the AWS services that it relies on, such as Amazon Personalize.</p> AWS Partner Workshops Overview Workshop Links Level Duration In this workshop, you will set up tracking for Amplitude events, analyze user behavior prior to peronalization being deployed, and then measure the effects of personalization on user behavior after Personalize is deployed in the Retail Demo Store. Evaluating Personalization Performance 200 30 minutes In this workshop we will use Braze to add the ability to personalize marketing messages to customers of the Retail Demo Store using customer behavioral data and the Personalize models you trained when setting up Amazon Personalize. Personalized Email Campaigns 200 1 hour mParticle is a Customer Data Platform that allows any brand to ingest data from multiple sources in real-time, apply data quality and governance over the ingested data and orchestrate the data to any marketing and technology stack your organization is using.  In this workshop, you will configure real-time event flows to Amazon Personalize using the mParticle SDKs and then use that data to create customer profiles that can be used in marketing campaigns to customers via Braze. Real Time Personalization Events Personalized Customer Profiles and Messaging with any marketing tool (Braze) and mParticle 300 1-1.5 hours In this exercise we will define, launch, and evaluate the results of an A/B experiment of a personalized user experience using Optimizely. AB Experiments for Personalization 200 30 minutes Segment is a real-time events pipeline for customer data, as well as a customer data platform.  In the Retail Demo Store, Segment is used to deliver real-time events from the web user interface to Amazon Personalize.  These real-time events are also used to create customer profile with Amazon Personalize recommendations appended, which can then be used via the CDP to push data to marketing tools. Real Time Personalization Events Customer Data Platforms and Personalize 300 1-1.5 hours Layer0 extends the capabilities of a traditional CDN by not only hosting your static content, but also providing server-side rendering for progressive web applications. Layer0 allows caching both your APIs and HTML at the network edge to provide your users with the fastest browsing experience. Teams can ship faster leveraging an enhanced developer experience to deploy code faster and with more frequency, view their code quickly in atomically deployed environments, and integrating their CDN configuration to the overall build process. Layer0 provides the tools needed to build the modern apps capable of providing the performance expected by modern consumers. Edge Optimization 200 1 hour"},{"location":"workshops/hands-on-workshops/","title":"Hands on workshops","text":"<p>This project is designed to provide you with an environment in which you can learn to use AWS services to modify the behavior of an ecommerce application, based on business requirements. This can be done in a group setting or as an individual using self-paced workbooks. Currently there are workshops for adding search, personalization, experimentation frameworks, a/b testing, analytics, customer data platforms (CDPs), messaging, and more.</p> <p>In order to use the workshops, you will need to deploy the Retail Demo Store into an AWS account, using one of the methods described in the Getting Started or Developers sections below.  This is necessary because the workshops run in SageMaker Jupyter notebooks, which provide an interactive Python environment where you can execute code in the Retail Demo Store environment.</p> AWS Service Workshops Overview Workshop Links Level Duration  Amazon Personalize The Retail Demo Store uses Amazon Personalize to provide similar item recommendations, search re-ranking based on user preferences, and product recommendations based on user item interactions.  The attached workshop is a throrough walk through of the major features of Amazon Personalize, and how it can be deployed in an ecommerce application like the Retail Demo Store. Personalize Setup 300 2-2.5 hours  Amazon Pinpoint In this workshop we will use Amazon Pinpoint to add the ability to dynamically send welcome messages, abandoned cart messages, and messages with personalized product recommendations to the customers of the Retail Demo Store. Email Campaigns 200 1 hour  Amazon Lex In this module we're going to implement a conversational chatbot using Amazon Lex and integrate it into the Retail Demo Store's web UI. We'll provide some basic functionality to our chatbot such as being able to provide a return policy to users as well as wiring up the chatbot to the Amazon Personalize ML models we created in the Personalization workshop to provide personalized product recommendations to our users. Lex Chatbot 200 30 minutes  Amazon OpenSearch In this workshop, you will create a new index using Amazon OpenSearch Service and then index the Retail Demo Store product data so that users can search for products. Product Search 200 20 minutes  Amazon Location Services Create a geofence for customers approaching your physical store and send them timely pickup notifications and offers. Geofencing 300 2 hours  Amazon Alexa Incorporating Location Service, Personalize and Retail Demo Store into a hands-free ordering experience. Alexa skill deployment 300 60 minutes Experimentation In this module we are going to add experimentation to the Retail Demo Store. This will allow us to experiment with different personalization approaches in the user interface. Through notebooks in this module we will demonstrate how to implement three experimentation techniques as well as how to use Amazon CloudWatch Evidently for A/B tests. Overview A/B (400) Interleaving (400) Multi-Armed Bandit (400) CloudWatch Evidently (200) 200/400 1.5 hours"}]}